"""
Telegram ‚Üí ChromaDB ingestor
----------------------------
CLI‚Äë—Å–∫—Ä–∏–ø—Ç, –∫–æ—Ç–æ—Ä—ã–π –∑–∞–≥—Ä—É–∂–∞–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏—è –ø—É–±–ª–∏—á–Ω–æ–≥–æ/–ø—Ä–∏–≤–∞—Ç–Ω–æ–≥–æ –∫–∞–Ω–∞–ª–∞ Telegram
–≤ —É–∫–∞–∑–∞–Ω–Ω–æ–º –¥–∏–∞–ø–∞–∑–æ–Ω–µ –¥–∞—Ç, —Ä–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç –≤—Å—Ç—Ä–∞–∏–≤–∞–Ω–∏—è (BGE‚Äëbase‚Äëv1.5 –∏–ª–∏ –¥—Ä—É–≥–∞—è
—É–∫–∞–∑–∞–Ω–Ω–∞—è –º–æ–¥–µ–ª—å) –∏ –ø–∞—á–∫–∞–º–∏ –ø–∏—à–µ—Ç –∏—Ö –≤ –∫–æ–ª–ª–µ–∫—Ü–∏—é ChromaDB.

–ó–∞–ø—É—Å–∫ (–ø—Ä–∏–º–µ—Ä):
$ python -m scripts.ingest_telegram \
      --channel @some_channel \
      --since 2024-06-01 \
      --until 2024-07-01 \
      --collection tg_some_channel

–û–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –ø–æ–ª–æ–∂–∏—Ç–µ –≤ .env:
TG_API_ID=123456
TG_API_HASH=abcdef0123456789abcdef0123456789
# –µ—Å–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç–µ user‚Äëaccount –ª–æ–≥–∏–Ω ‚Üí TG_PHONE=+79995555555
# –ª–∏–±–æ BOT_TOKEN=123456:ABC‚ÄëDEF‚Ä¶ (—Ç–æ–≥–¥–∞ –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è –ø–æ –±–æ—Ç—É)

CHROMA_HOST=localhost
CHROMA_PORT=8000

–°–∫—Ä–∏–ø—Ç –±–µ–∑–æ–ø–∞—Å–Ω–æ –ø—Ä–æ–¥–æ–ª–∂–∏—Ç —Ä–∞–±–æ—Ç—É –ø–æ—Å–ª–µ –æ–±—Ä—ã–≤–∞ —Å–µ—Ç–∏ –∏–ª–∏ FloodWait,
–ø–∏—à–µ—Ç –ø—Ä–æ–≥—Ä–µ—Å—Å –∏ –æ–∂–∏–¥–∞–µ–º–æ–µ –≤—Ä–µ–º—è –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è.
"""

from __future__ import annotations

import asyncio
import os
import sys
import uuid
import logging
import argparse
from datetime import datetime, timezone
from typing import List, Optional, Dict, Any

from dotenv import load_dotenv
from tqdm.asyncio import tqdm_asyncio
from dateutil import parser as date_parser, tz

from telethon import TelegramClient, errors as tg_errors, events
from telethon.errors import FloodWaitError, SessionPasswordNeededError
from telethon.tl.types import Message

import numpy as np
import chromadb
from chromadb.utils.embedding_functions import SentenceTransformerEmbeddingFunction
import torch
from sentence_transformers import SentenceTransformer

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# Config & CLI parsing
# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ


def _parse_args() -> argparse.Namespace:
    p = argparse.ArgumentParser(description="Ingest Telegram channel(s) into ChromaDB")
    p.add_argument(
        "--channel", required=False, default=None, help="@username or chat id"
    )
    p.add_argument(
        "--channels",
        required=False,
        default=None,
        help="Comma-separated list of channels, e.g. @a,@b,@c",
    )
    p.add_argument("--since", required=True, help="ISO date (inclusive)")
    p.add_argument("--until", required=True, help="ISO date (exclusive)")
    p.add_argument("--collection", required=True, help="Chroma collection name")
    p.add_argument(
        "--batch-size",
        type=int,
        default=None,
        help="Batch size (auto-detected based on device)",
    )
    p.add_argument(
        "--embed-model-key", default=None, help="Embedding model key from config"
    )
    p.add_argument(
        "--embed-model", default=None, help="Direct embedding model name (fallback)"
    )
    p.add_argument("--device", default="auto", help="Device: auto, cpu, cuda, mps")
    p.add_argument(
        "--max-messages",
        type=int,
        default=None,
        help="ingest N newest messages then stop (debug)",
    )
    p.add_argument(
        "--chunk-size",
        type=int,
        default=0,
        help="Split long messages into chunks of N chars (0 = no split)",
    )
    p.add_argument("--log-level", default="INFO")
    p.add_argument(
        "--gpu-batch-multiplier", type=int, default=4, help="GPU batch size multiplier"
    )
    return p.parse_args()


load_dotenv()

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# Logger
# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
logger = logging.getLogger("ingest_telegram")
handler = logging.StreamHandler(sys.stdout)
handler.setFormatter(logging.Formatter("%(asctime)s [%(levelname)s] %(message)s"))
logger.addHandler(handler)
logger.setLevel(os.getenv("LOG_LEVEL", "INFO"))

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# Telegram utils
# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ


async def create_telegram_client() -> TelegramClient:
    api_id_str = os.getenv("TG_API_ID")
    if not api_id_str:
        logger.error("TG_API_ID not set; add it to .env or environment")
        sys.exit(1)
    api_id = int(api_id_str)
    api_hash = os.getenv("TG_API_HASH")
    # Persist session file to avoid re-auth every run. Using TG_SESSION allows
    # passing an absolute path (e.g. a mounted Docker volume). If the path
    # points to a directory, we append the default filename so Telethon gets a
    # valid file path.
    session_path_env = os.getenv("TG_SESSION", "telegram.session")
    # Expand tilde and make absolute for safety
    session_path = os.path.expanduser(session_path_env)
    if os.path.isdir(session_path):
        session_path = os.path.join(session_path, "telegram.session")

    # Ensure parent dir exists so Telethon can write the session file even in a
    # freshly mounted volume.
    parent_dir = os.path.dirname(session_path)
    if parent_dir:
        os.makedirs(parent_dir, exist_ok=True)

    phone = os.getenv("TG_PHONE")
    bot_token = os.getenv("BOT_TOKEN")

    if not (api_id and api_hash):
        logger.error("TG_API_ID and TG_API_HASH must be set in environment")
        sys.exit(1)

    client = TelegramClient(session_path, api_id, api_hash, device_model="RAG-Scraper")
    await client.connect()

    if not await client.is_user_authorized():
        if bot_token:
            await client.start(bot_token=bot_token)
        elif phone:
            await client.send_code_request(phone)
            code = input("Enter the code you just received: ")
            try:
                await client.sign_in(phone, code)
            except SessionPasswordNeededError:
                pwd = input("Two‚Äëfactor enabled. Enter your password: ")
                await client.sign_in(password=pwd)
        else:
            logger.error("Provide BOT_TOKEN or TG_PHONE for authorization.")
            sys.exit(1)
    return client


# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# Chroma utils
# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ


def detect_optimal_device() -> str:
    """–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç –ª—É—á—à–µ–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ –¥–ª—è –≤—ã—á–∏—Å–ª–µ–Ω–∏–π"""
    if torch.cuda.is_available():
        logger.info(f"üöÄ CUDA –¥–æ—Å—Ç—É–ø–Ω–∞: {torch.cuda.get_device_name(0)}")
        return "cuda"
    elif hasattr(torch.backends, "mps") and torch.backends.mps.is_available():
        logger.info("üöÄ MPS (Apple Silicon) –¥–æ—Å—Ç—É–ø–µ–Ω")
        return "mps"
    else:
        logger.info("üíª –ò—Å–ø–æ–ª—å–∑—É–µ–º CPU")
        return "cpu"


def get_optimal_batch_size(
    device: str, base_batch_size: int = 64, gpu_multiplier: int = 4
) -> int:
    """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä –±–∞—Ç—á–∞ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞"""
    if device in ["cuda", "mps"]:
        optimal_size = base_batch_size * gpu_multiplier
        logger.info(f"üìä GPU detected, increasing batch size to {optimal_size}")
        return optimal_size
    else:
        logger.info(f"üìä CPU detected, using batch size {base_batch_size}")
        return base_batch_size


def resolve_embedding_model(
    embed_model_key: Optional[str], embed_model: Optional[str]
) -> str:
    """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –º–æ–¥–µ–ª—å embedding –∏–∑ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –∏–ª–∏ fallback"""
    # –ü–æ–ø—ã—Ç–∫–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –∏–∑ .env –∫–∞–∫ –≤ API
    if not embed_model_key:
        embed_model_key = os.getenv("EMBEDDING_MODEL_KEY", "multilingual-e5-large")

    # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –º–æ–¥–µ–ª–µ–π
    try:
        import sys
        from pathlib import Path

        # –î–æ–±–∞–≤–ª—è–µ–º src –≤ –ø—É—Ç—å
        src_path = Path(__file__).parent.parent / "src"
        if str(src_path) not in sys.path:
            sys.path.insert(0, str(src_path))

        from utils.model_downloader import RECOMMENDED_MODELS

        if embed_model_key in RECOMMENDED_MODELS["embedding"]:
            model_name = RECOMMENDED_MODELS["embedding"][embed_model_key]["name"]
            logger.info(f"üéØ –ò—Å–ø–æ–ª—å–∑—É–µ–º –º–æ–¥–µ–ª—å –∏–∑ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏: {model_name}")
            return model_name
    except Exception as e:
        logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –º–æ–¥–µ–ª–µ–π: {e}")

    # Fallback
    if embed_model:
        logger.info(f"üéØ –ò—Å–ø–æ–ª—å–∑—É–µ–º —É–∫–∞–∑–∞–Ω–Ω—É—é –º–æ–¥–µ–ª—å: {embed_model}")
        return embed_model

    # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é –¥–ª—è —Ä—É—Å—Å–∫–æ–≥–æ —è–∑—ã–∫–∞
    default_model = os.getenv("EMBEDDING_MODEL", "intfloat/multilingual-e5-large")
    logger.info(f"üéØ –ò—Å–ø–æ–ª—å–∑—É–µ–º –º–æ–¥–µ–ª—å –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: {default_model}")
    return default_model


class FastEmbeddingFunction:
    """–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è embedding —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π GPU –∏ –±–∞—Ç—á–∏–Ω–≥–∞"""

    def __init__(self, model_name: str, device: str):
        self.model_name = model_name
        self.device = device
        logger.info(f"‚ö° –ó–∞–≥—Ä—É–∂–∞–µ–º embedding –º–æ–¥–µ–ª—å: {model_name} –Ω–∞ {device}")
        self.model = SentenceTransformer(model_name, device=device)
        if device in ["cuda", "mps"]:
            try:
                self.model.half()
            except AttributeError:
                pass
            logger.info("üî• –í–∫–ª—é—á–µ–Ω–∞ GPU –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è")

    # sig must be (self, input)
    def __call__(self, input):
        if not input:
            return np.empty((0, 768), dtype=np.float32)
        with torch.no_grad():
            emb = self.model.encode(
                input,
                convert_to_tensor=False,  # np.ndarray
                device=self.device,
                show_progress_bar=False,
                batch_size=32 if self.device == "cpu" else 128,
            )
            return emb


def create_chroma_collection(name: str, embed_model: str, device: str):
    """Connect to Chroma HTTP server and obtain (or create) a collection.

    The Chroma Python API changed multiple times; we probe the available
    symbols/parameters at runtime so that the script works with 0.4.x and
    newer versions alike."""

    # ---------------------------
    # Build embedding function
    # ---------------------------
    from inspect import signature

    hf_kwargs: Dict[str, Any] = {"model_name": embed_model}

    sig = signature(SentenceTransformerEmbeddingFunction)

    if "device" in sig.parameters:
        hf_kwargs["device"] = device
    elif "device_type" in sig.parameters:
        hf_kwargs["device_type"] = device

    # Optional normalization flag changed name across versions.
    if "normalize" in sig.parameters:
        hf_kwargs["normalize"] = True
    elif "normalize_embeddings" in sig.parameters:
        hf_kwargs["normalize_embeddings"] = True

    # –î–æ–±–∞–≤–ª—è–µ–º –∫–ª—é—á HuggingFace –∏–∑ –æ–∫—Ä—É–∂–µ–Ω–∏—è, –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω,
    # —Ç–∞–∫ –∫–∞–∫ –Ω–æ–≤—ã–µ –≤–µ—Ä—Å–∏–∏ chromadb —Ç—Ä–µ–±—É—é—Ç –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ–≥–æ `api_key`.
    api_key = os.getenv("CHROMA_HUGGINGFACE_API_KEY") or os.getenv(
        "HUGGINGFACE_API_KEY"
    )
    if api_key:
        if "api_key" in sig.parameters:
            hf_kwargs["api_key"] = api_key
        elif "huggingface_api_key" in sig.parameters:
            hf_kwargs["huggingface_api_key"] = api_key

    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –Ω–∞—à—É –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—É—é —Ñ—É–Ω–∫—Ü–∏—é embedding
    try:
        embed_fn = FastEmbeddingFunction(embed_model, device)
        logger.info(f"‚úÖ –ò—Å–ø–æ–ª—å–∑—É–µ–º –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—É—é embedding —Ñ—É–Ω–∫—Ü–∏—é")
    except Exception as e:
        logger.warning(f"Fallback –Ω–∞ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—É—é embedding —Ñ—É–Ω–∫—Ü–∏—é: {e}")
        embed_fn = SentenceTransformerEmbeddingFunction(**hf_kwargs)

    # ---------------------------
    # Connect to Chroma
    # ---------------------------
    host = os.getenv("CHROMA_HOST", "localhost")
    port = int(os.getenv("CHROMA_PORT", 8000))

    if hasattr(chromadb, "HttpClient"):
        client = chromadb.HttpClient(host=host, port=port)
    else:
        # Fallback to old API
        client = chromadb.Client(host=host, port=port)

    # ---------------------------
    # Get or create collection (with embedding function attached)
    # ---------------------------
    try:
        collection = client.get_collection(name, embedding_function=embed_fn)
        logger.info("Using existing collection %s (count=%s)", name, collection.count())
    except Exception as e:
        # get_collection may raise NotFoundError (old API) or ValueError (newer)
        logger.debug("Collection %s not found (%s), creating new", name, e)
        collection = client.create_collection(
            name,
            metadata={"hnsw:space": "cosine"},
            embedding_function=embed_fn,
        )
        logger.info("Created new collection %s", name)

    return collection


# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# Batch helpers
# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ


def split_into_batches(seq: List[Any], batch_size: int):
    for i in range(0, len(seq), batch_size):
        yield seq[i : i + batch_size]


def estimate_processing_time(total_messages: int, batch_size: int, device: str) -> str:
    """–û—Ü–µ–Ω–∏–≤–∞–µ—Ç –≤—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞"""
    # –ü—Ä–∏–º–µ—Ä–Ω—ã–µ —Å–∫–æ—Ä–æ—Å—Ç–∏ (—Å–æ–æ–±—â–µ–Ω–∏–π –≤ —Å–µ–∫—É–Ω–¥—É)
    speeds = {
        "cuda": 100,  # ~100 —Å–æ–æ–±—â–µ–Ω–∏–π/—Å–µ–∫ –Ω–∞ GPU
        "cpu": 5,  # ~5 —Å–æ–æ–±—â–µ–Ω–∏–π/—Å–µ–∫ –Ω–∞ CPU
    }

    speed = speeds.get(device, 5)
    estimated_seconds = total_messages / speed

    if estimated_seconds < 60:
        return f"{estimated_seconds:.0f} —Å–µ–∫—É–Ω–¥"
    elif estimated_seconds < 3600:
        return f"{estimated_seconds/60:.1f} –º–∏–Ω—É—Ç"
    else:
        return f"{estimated_seconds/3600:.1f} —á–∞—Å–æ–≤"


async def gather_messages(
    client: TelegramClient,
    channel: str,
    start: datetime,
    end: datetime,
    limit: Optional[int] = None,
) -> List[Message]:
    """Fetch messages with *start* ‚â§ date < *end*.

    Telegram's API returns history in reverse-chronological order by default
    (newest ‚Üí oldest). We leverage that to avoid walking the whole history of
    busy channels: request messages older than *end* and stop once we cross
    *start*."""

    collected: List[Message] = []

    # Request messages older-than `end` (exclusive). We keep the default
    # order (newest‚Üíoldest) so once we reach dates older than `start` we can
    # break early.
    async for msg in client.iter_messages(channel, offset_date=end):
        # Message dates from Telethon are timezone-aware UTC; normalise for
        # reliable comparisons.
        msg_dt = _to_utc_naive(msg.date)

        if msg_dt < start:
            break  # we went past the desired range
        if msg_dt >= end:
            continue  # should not normally happen, but be safe

        if not (msg.message and msg.message.strip()):
            continue  # skip non-text and service messages

        collected.append(msg)

        if limit and len(collected) >= limit:
            break

    # We collected newest‚Üíoldest; reverse to chronological order for nicer
    # batching/ingestion.
    collected.reverse()
    return collected


def _split_text(text: str, chunk_size: int) -> List[str]:
    if chunk_size and chunk_size > 0 and len(text) > chunk_size:
        return [text[i : i + chunk_size] for i in range(0, len(text), chunk_size)]
    return [text]


# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# Resilience helpers
# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ


async def _gather_with_retries(
    client: TelegramClient,
    channel: str,
    start: datetime,
    end: datetime,
    limit: Optional[int] = None,
    max_retries: int = 5,
):
    attempt = 0
    while True:
        try:
            return await gather_messages(client, channel, start, end, limit)
        except FloodWaitError as e:
            wait_s = int(getattr(e, "seconds", 0) or 0) or 60
            logger.warning(
                "FloodWait channel=%s: –∂–¥—ë–º %ss (attempt %d/%d)",
                channel,
                wait_s,
                attempt + 1,
                max_retries,
            )
            await asyncio.sleep(wait_s + min(30, attempt * 5))
        except (tg_errors.RPCError, OSError) as e:
            if attempt >= max_retries - 1:
                logger.error("–ò—Å—á–µ—Ä–ø–∞–Ω—ã —Ä–µ—Ç—Ä–∞–∏ —Å–±–æ—Ä–∞ —Å–æ–æ–±—â–µ–Ω–∏–π –¥–ª—è %s: %s", channel, e)
                raise
            backoff = min(60, (2**attempt) * 2)
            logger.warning(
                "–°–µ—Ç–µ–≤–∞—è –æ—à–∏–±–∫–∞ –¥–ª—è %s: %s. –ü–æ–≤—Ç–æ—Ä —á–µ—Ä–µ–∑ %ss (attempt %d/%d)",
                channel,
                e,
                backoff,
                attempt + 1,
                max_retries,
            )
            await asyncio.sleep(backoff)
        attempt += 1


async def ingest_batches(
    collection_name: str,
    collection,
    messages: List[Message],
    batch_size: int,
    chunk_size: int = 0,
    channel_hint: Optional[str] = None,
    progress_cb: Optional[Any] = None,
    log_every: int = 200,
):
    total = len(messages)
    processed_in_channel = 0
    total_written_chroma = 0
    total_written_bm25 = 0
    import time as _time

    start_ts = _time.time()
    last_log_ts = start_ts
    for batch in tqdm_asyncio(
        split_into_batches(messages, batch_size),
        total=(total // batch_size) + 1,
        desc="Ingesting",
        unit="batch",
    ):
        docs: List[str] = []
        ids: List[str] = []
        metas: List[Dict[str, Any]] = []
        bm25_docs_local: List[Any] = []

        for m in batch:
            text = (m.message or "").strip()
            if not text:
                continue
            parts = _split_text(text, chunk_size)
            for idx, part in enumerate(parts):
                docs.append(part)
                # –î–µ—Ç–µ—Ä–º–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π id: channel:msg:chunk
                ids.append(f"{m.chat_id}:{m.id}:{idx}")
                meta = {
                    "channel_id": m.chat_id,
                    "msg_id": m.id,
                    "date": m.date.isoformat(),
                }
                if (
                    channel_hint
                    and isinstance(channel_hint, str)
                    and channel_hint.startswith("@")
                ):
                    meta["channel_username"] = channel_hint
                if m.reply_to_msg_id is not None:
                    meta["reply_to"] = m.reply_to_msg_id
                views = getattr(m, "views", None)
                if views is not None:
                    meta["views"] = views
                metas.append(meta)

                # BM25 –¥–æ–∫—É–º–µ–Ω—Ç –ø–æ –∫–∞–∂–¥–æ–º—É —á–∞–Ω–∫—É
                try:
                    from adapters.search.bm25_index import BM25Doc
                except Exception:
                    BM25Doc = None  # type: ignore
                if BM25Doc is not None:
                    date_iso = _to_utc_naive(m.date).date().isoformat()
                    date_days = _to_utc_naive(m.date).date().toordinal()
                    bm25_docs_local.append(
                        BM25Doc(
                            doc_id=f"{m.chat_id}:{m.id}:{idx}",
                            text=" ".join(part.split()),
                            channel_id=int(m.chat_id),
                            channel_username=(
                                channel_hint
                                if (
                                    isinstance(channel_hint, str)
                                    and channel_hint.startswith("@")
                                )
                                else None
                            ),
                            date_days=int(date_days),
                            date_iso=date_iso,
                            views=getattr(m, "views", None),
                            reply_to=getattr(m, "reply_to_msg_id", None),
                            msg_id=int(m.id),
                        )
                    )

        try:
            if hasattr(collection, "upsert"):
                collection.upsert(documents=docs, metadatas=metas, ids=ids)
            else:
                collection.add(documents=docs, metadatas=metas, ids=ids)
            total_written_chroma += len(ids)
        except Exception as e:
            logger.exception("Failed on batch, skipping‚Ä¶ (%s)", e)

        # BM25: –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ (–±–∞—Ç—á)
        try:
            from adapters.search.bm25_index import BM25IndexManager
            from core.settings import get_settings

            settings = get_settings()
            bm25_root = settings.bm25_index_root
            mgr = BM25IndexManager(index_root=bm25_root)
            if bm25_docs_local:
                mgr.add_documents(
                    collection=collection_name, docs=bm25_docs_local, commit_every=1000
                )
                total_written_bm25 += len(bm25_docs_local)
        except Exception as e:
            logger.warning(f"BM25 add_documents failed: {e}")

        processed_in_channel += len(batch)
        # –ü–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∏–µ –ª–æ–≥–∏
        should_log = (processed_in_channel % max(1, log_every) == 0) or (
            processed_in_channel >= total
        )
        totals_from_cb = None
        if progress_cb is not None:
            try:
                totals_from_cb = progress_cb(
                    {
                        "processed_in_channel": processed_in_channel,
                        "written_chroma": total_written_chroma,
                        "written_bm25": total_written_bm25,
                        "batch_size": len(batch),
                        "total_in_channel": total,
                    }
                )
            except Exception:
                totals_from_cb = None
        if should_log:
            now = _time.time()
            elapsed = now - start_ts
            step_elapsed = now - last_log_ts
            last_log_ts = now
            speed = (processed_in_channel / elapsed) if elapsed > 0 else 0.0
            if isinstance(totals_from_cb, dict):
                logger.info(
                    "progress channel=%s processed_in_channel=%d/%d processed_total=%s written_chroma=%d written_bm25=%d elapsed_s=%.1f speed_msg_s=%.1f",
                    (channel_hint or "?"),
                    processed_in_channel,
                    total,
                    totals_from_cb.get("processed_total", "-"),
                    total_written_chroma,
                    total_written_bm25,
                    step_elapsed,
                    speed,
                )
            else:
                logger.info(
                    "progress channel=%s processed_in_channel=%d/%d written_chroma=%d written_bm25=%d elapsed_s=%.1f speed_msg_s=%.1f",
                    (channel_hint or "?"),
                    processed_in_channel,
                    total,
                    total_written_chroma,
                    total_written_bm25,
                    step_elapsed,
                    speed,
                )

    return {
        "processed_in_channel": processed_in_channel,
        "written_chroma": total_written_chroma,
        "written_bm25": total_written_bm25,
        "total_in_channel": total,
    }


# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# Date helpers
# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ


def _to_utc_naive(dt: datetime) -> datetime:
    """Return timezone-naive UTC datetime for reliable comparison with
    Telegram timestamps (which Telethon returns as naive UTC)."""
    if dt.tzinfo is None:
        return dt
    return dt.astimezone(timezone.utc).replace(tzinfo=None)


# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# Checkpoint stubs (not used yet)
# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ


def load_state(
    path: str = os.path.join(
        os.path.dirname(__file__), "sessions", "telegram_ingest.state.json"
    )
) -> Dict[str, Any]:
    try:
        import json

        os.makedirs(os.path.dirname(path), exist_ok=True)
        if not os.path.exists(path):
            logger.info(
                "[checkpoint] state —Ñ–∞–π–ª –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç: %s (–ø–æ–∫–∞ –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è)", path
            )
            return {}
        with open(path, "r", encoding="utf-8") as f:
            return json.load(f)
    except Exception as e:
        logger.warning("[checkpoint] –Ω–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å state: %s", e)
        return {}


def save_state(
    state: Dict[str, Any],
    path: str = os.path.join(
        os.path.dirname(__file__), "sessions", "telegram_ingest.state.json"
    ),
) -> None:
    try:
        import json

        os.makedirs(os.path.dirname(path), exist_ok=True)
        with open(path, "w", encoding="utf-8") as f:
            json.dump(state, f, ensure_ascii=False, indent=2)
        logger.info("[checkpoint] state —Å–æ—Ö—Ä–∞–Ω—ë–Ω: %s (–ø–æ–∫–∞ –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è)", path)
    except Exception as e:
        logger.warning("[checkpoint] –Ω–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å state: %s", e)


# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# Main
# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ


async def main():
    args = _parse_args()
    logger.setLevel(args.log_level.upper())

    # –°–æ–±–∏—Ä–∞–µ–º –∏—Ç–æ–≥–æ–≤—ã–π —Å–ø–∏—Å–æ–∫ –∫–∞–Ω–∞–ª–æ–≤
    channels: List[str] = []
    if getattr(args, "channel", None):
        channels.append(args.channel)
    if getattr(args, "channels", None):
        for part in str(args.channels).split(","):
            part = part.strip()
            if part:
                channels.append(part)
    seen = set()
    channels = [c for c in channels if not (c in seen or seen.add(c))]
    if not channels:
        logger.error("–ù–µ —É–∫–∞–∑–∞–Ω –Ω–∏ –æ–¥–∏–Ω –∫–∞–Ω–∞–ª. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ --channel –∏–ª–∏ --channels")
        sys.exit(2)

    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ
    if args.device == "auto":
        device = detect_optimal_device()
    else:
        device = args.device
        logger.info(f"üéØ –ò—Å–ø–æ–ª—å–∑—É–µ–º —É–∫–∞–∑–∞–Ω–Ω–æ–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {device}")

    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –º–æ–¥–µ–ª—å embedding
    embed_model = resolve_embedding_model(args.embed_model_key, args.embed_model)

    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä –±–∞—Ç—á–∞
    if args.batch_size is None:
        batch_size = get_optimal_batch_size(
            device, gpu_multiplier=args.gpu_batch_multiplier
        )
    else:
        batch_size = args.batch_size
        logger.info(f"üìä –ò—Å–ø–æ–ª—å–∑—É–µ–º —É–∫–∞–∑–∞–Ω–Ω—ã–π batch size: {batch_size}")

    start_iso = _to_utc_naive(date_parser.isoparse(args.since))
    end_iso = _to_utc_naive(date_parser.isoparse(args.until))

    logger.info("üîó –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ Telegram‚Ä¶")
    client = await create_telegram_client()
    try:
        logger.info(
            "üîó –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ ChromaDB %s:%s",
            os.getenv("CHROMA_HOST", "localhost"),
            os.getenv("CHROMA_PORT", 8000),
        )

        # –ê–≤—Ç–æ—Å–∫–∞—á–∏–≤–∞–Ω–∏–µ embedding –º–æ–¥–µ–ª–∏ –µ—Å–ª–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ
        try:
            auto_download = (
                os.getenv("AUTO_DOWNLOAD_EMBEDDING", "true").lower() == "true"
            )
            if auto_download:
                logger.info("üì• –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏ —Å–∫–∞—á–∏–≤–∞–Ω–∏–µ embedding –º–æ–¥–µ–ª–∏...")
                import sys as _sys
                from pathlib import Path as _Path

                src_path = _Path(__file__).parent.parent / "src"
                if str(src_path) not in _sys.path:
                    _sys.path.insert(0, str(src_path))

                from utils.model_downloader import download_embedding_model

                cache_dir = os.getenv("TRANSFORMERS_CACHE", "/models/.cache")
                download_embedding_model(embed_model, cache_dir)
        except Exception as e:
            logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∞–≤—Ç–æ—Å–∫–∞—á–∞—Ç—å –º–æ–¥–µ–ª—å: {e}")

        collection = create_chroma_collection(args.collection, embed_model, device)

        total_processed = 0
        total_written_chroma = 0
        total_written_bm25 = 0

        def _progress_cb(batch_stats: Dict[str, Any]):
            nonlocal total_processed, total_written_chroma, total_written_bm25
            total_processed += int(batch_stats.get("batch_size", 0))
            total_written_chroma = int(batch_stats.get("written_chroma", 0))
            total_written_bm25 = int(batch_stats.get("written_bm25", 0))
            logger.debug(
                "progress_total processed_total=%d written_chroma_total=%d written_bm25_total=%d",
                total_processed,
                total_written_chroma,
                total_written_bm25,
            )
            return {
                "processed_total": total_processed,
                "written_chroma_total": total_written_chroma,
                "written_bm25_total": total_written_bm25,
            }

        for ch in channels:
            logger.info(
                "‚ñ∂ start channel=%s dates=%s‚Üí%s", ch, start_iso.date(), end_iso.date()
            )

            msgs = await _gather_with_retries(
                client, ch, start_iso, end_iso, args.max_messages
            )
            logger.info("üì® –ü–æ–ª—É—á–µ–Ω–æ %s —Å–æ–æ–±—â–µ–Ω–∏–π –¥–ª—è %s", len(msgs), ch)
            if not msgs:
                logger.warning("–ü—É—Å—Ç–æ –¥–ª—è %s ‚Äî –ø—Ä–æ–ø—É—Å–∫–∞–µ–º", ch)
                continue

            estimated_time = estimate_processing_time(len(msgs), batch_size, device)
            est_batches = (len(msgs) + batch_size - 1) // batch_size
            logger.info(
                "‚è±Ô∏è –û—Ü–µ–Ω–∫–∞: %s, –±–∞—Ç—á–µ–π ~%d (batch_size=%d)",
                estimated_time,
                est_batches,
                batch_size,
            )

            logger.info(
                f"üöÄ –ù–∞—á–∏–Ω–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É –∫–∞–Ω–∞–ª–∞ {ch} –Ω–∞ {device.upper()} —Å batch_size={batch_size}"
            )

            stats = await ingest_batches(
                args.collection,
                collection,
                msgs,
                batch_size,
                chunk_size=int(getattr(args, "chunk_size", 0) or 0),
                channel_hint=ch if isinstance(ch, str) else None,
                progress_cb=_progress_cb,
                log_every=200,
            )

            logger.info(
                "‚úî finish channel=%s read=%d written_chroma=%d written_bm25=%d",
                ch,
                stats.get("processed_in_channel", 0),
                stats.get("written_chroma", 0),
                stats.get("written_bm25", 0),
            )

        final_count = collection.count()
        logger.info(
            "üèÅ –í—Å–µ –∫–∞–Ω–∞–ª—ã –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã. –í –∫–æ–ª–ª–µ–∫—Ü–∏–∏ —Ç–µ–ø–µ—Ä—å: %s –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤",
            final_count,
        )

        # –ü—É—Ç—å –∫ BM25 –∏–Ω–¥–µ–∫—Å—É (–µ—Å–ª–∏ –≤–∫–ª—é—á—ë–Ω)
        try:
            from adapters.search.bm25_index import BM25IndexManager
            from core.settings import get_settings

            settings = get_settings()
            bm25_root = settings.bm25_index_root
            mgr = BM25IndexManager(index_root=bm25_root)
            handle = mgr.get_or_create(args.collection)
            logger.info(
                "BM25 index path for collection '%s': %s",
                args.collection,
                handle.paths.get("root"),
            )
        except Exception as e:
            logger.warning(f"BM25 unavailable or disabled: {e}")

    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤–æ –≤—Ä–µ–º—è –∏–Ω–∂–µ—Å—Ç–∞: {e}")
        raise
    finally:
        await client.disconnect()


if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        logger.info("Interrupted by user")
