#!/usr/bin/env python3
"""
CLI —Å–∫—Ä–∏–ø—Ç –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è –º–æ–¥–µ–ª–µ–π
"""
import argparse
import os
import sys
from pathlib import Path

# –î–æ–±–∞–≤–ª—è–µ–º src –≤ –ø—É—Ç—å –¥–ª—è –∏–º–ø–æ—Ä—Ç–æ–≤
sys.path.insert(0, str(Path(__file__).parent.parent))

from utils.model_downloader import auto_download_models, RECOMMENDED_MODELS
import logging

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s"
)


def main():
    parser = argparse.ArgumentParser(
        description="–°–∫–∞—á–∏–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–µ–π –¥–ª—è RAG —Å–∏—Å—Ç–µ–º—ã",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
–ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è:

  # –°–∫–∞—á–∞—Ç—å —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–µ –º–æ–¥–µ–ª–∏ –¥–ª—è —Ä—É—Å—Å–∫–æ–≥–æ —è–∑—ã–∫–∞
  python download_models.py

  # –°–∫–∞—á–∞—Ç—å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –º–æ–¥–µ–ª–∏
      python download_models.py --llm vikhr-7b-instruct --embedding multilingual-e5-large

  # –ü–æ–∫–∞–∑–∞—Ç—å –¥–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏
  python download_models.py --list

  # –°–∫–∞—á–∞—Ç—å –≤ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—É—é –ø–∞–ø–∫—É
  python download_models.py --models-dir /path/to/models
        """,
    )

    parser.add_argument(
        "--llm",
        choices=list(RECOMMENDED_MODELS["llm"].keys()),
        default="vikhr-7b-instruct",
        help="LLM –º–æ–¥–µ–ª—å –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è",
    )

    parser.add_argument(
        "--embedding",
        choices=list(RECOMMENDED_MODELS["embedding"].keys()),
        default="multilingual-e5-large",
        help="Embedding –º–æ–¥–µ–ª—å –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è",
    )

    parser.add_argument(
        "--models-dir", default="/models", help="–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π"
    )

    parser.add_argument(
        "--cache-dir", default="/models/.cache", help="–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –∫—ç—à–∞ HuggingFace"
    )

    parser.add_argument(
        "--list", action="store_true", help="–ü–æ–∫–∞–∑–∞—Ç—å —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π"
    )

    parser.add_argument(
        "--llm-only", action="store_true", help="–°–∫–∞—á–∞—Ç—å —Ç–æ–ª—å–∫–æ LLM –º–æ–¥–µ–ª—å"
    )

    parser.add_argument(
        "--embedding-only", action="store_true", help="–°–∫–∞—á–∞—Ç—å —Ç–æ–ª—å–∫–æ embedding –º–æ–¥–µ–ª—å"
    )

    args = parser.parse_args()

    # –ü–æ–∫–∞–∑–∞—Ç—å —Å–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π
    if args.list:
        print("ü§ñ –î–æ—Å—Ç—É–ø–Ω—ã–µ LLM –º–æ–¥–µ–ª–∏:")
        for key, config in RECOMMENDED_MODELS["llm"].items():
            print(f"  {key}: {config['description']}")
            print(f"    –§–∞–π–ª: {config['filename']}")
            print()

        print("üìä –î–æ—Å—Ç—É–ø–Ω—ã–µ Embedding –º–æ–¥–µ–ª–∏:")
        for key, config in RECOMMENDED_MODELS["embedding"].items():
            print(f"  {key}: {config['description']}")
            print(f"    –ú–æ–¥–µ–ª—å: {config['name']}")
            print()
        return

    # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
    os.makedirs(args.models_dir, exist_ok=True)
    os.makedirs(args.cache_dir, exist_ok=True)

    print("üöÄ –ó–∞–ø—É—Å–∫ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è –º–æ–¥–µ–ª–µ–π...")
    print(f"üìÅ –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –º–æ–¥–µ–ª–µ–π: {args.models_dir}")
    print(f"üíæ –ö—ç—à: {args.cache_dir}")
    print()

    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —á—Ç–æ —Å–∫–∞—á–∏–≤–∞—Ç—å
    llm_key = args.llm if not args.embedding_only else ""
    embedding_key = args.embedding if not args.llm_only else ""

    if llm_key:
        print(f"üß† LLM –º–æ–¥–µ–ª—å: {RECOMMENDED_MODELS['llm'][llm_key]['description']}")
    if embedding_key:
        print(
            f"üìä Embedding –º–æ–¥–µ–ª—å: {RECOMMENDED_MODELS['embedding'][embedding_key]['description']}"
        )
    print()

    # –°–∫–∞—á–∏–≤–∞–µ–º –º–æ–¥–µ–ª–∏
    llm_path, embedding_success = auto_download_models(
        llm_model_key=llm_key,
        embedding_model_key=embedding_key,
        models_dir=args.models_dir,
        cache_dir=args.cache_dir,
    )

    # –†–µ–∑—É–ª—å—Ç–∞—Ç—ã
    print("\n" + "=" * 50)
    print("üìä –†–ï–ó–£–õ–¨–¢–ê–¢–´ –°–ö–ê–ß–ò–í–ê–ù–ò–Ø:")

    if llm_key:
        if llm_path:
            print(f"‚úÖ LLM –º–æ–¥–µ–ª—å: {llm_path}")
        else:
            print("‚ùå LLM –º–æ–¥–µ–ª—å: –Ω–µ —É–¥–∞–ª–æ—Å—å —Å–∫–∞—á–∞—Ç—å")

    if embedding_key:
        if embedding_success:
            print(f"‚úÖ Embedding –º–æ–¥–µ–ª—å: —É—Å–ø–µ—à–Ω–æ —Å–∫–∞—á–∞–Ω–∞")
        else:
            print("‚ùå Embedding –º–æ–¥–µ–ª—å: –Ω–µ —É–¥–∞–ª–æ—Å—å —Å–∫–∞—á–∞—Ç—å")

    if (not llm_key or llm_path) and (not embedding_key or embedding_success):
        print("\nüéâ –í—Å–µ –º–æ–¥–µ–ª–∏ —É—Å–ø–µ—à–Ω–æ —Å–∫–∞—á–∞–Ω—ã!")
        print("\n–¢–µ–ø–µ—Ä—å –º–æ–∂–µ—Ç–µ –∑–∞–ø—É—Å—Ç–∏—Ç—å API:")
        print("docker compose --profile api up")
        return 0
    else:
        print("\n‚ö†Ô∏è –ù–µ–∫–æ—Ç–æ—Ä—ã–µ –º–æ–¥–µ–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å —Å–∫–∞—á–∞—Ç—å")
        return 1


if __name__ == "__main__":
    sys.exit(main())
